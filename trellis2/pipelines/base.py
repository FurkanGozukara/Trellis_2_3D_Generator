from typing import *
import torch
import torch.nn as nn
from .. import models


class Pipeline:
    """
    A base class for pipelines.
    """
    def __init__(
        self,
        models: dict[str, nn.Module] = None,
    ):
        if models is None:
            return
        self.models = models
        for model in self.models.values():
            model.eval()

    @classmethod
    def from_pretrained(cls, path: str, ignore_models: List[str] = None, config_file: str = "pipeline.json") -> "Pipeline":
        """
        Load a pretrained model.
        """
        import os
        import json

        # Prefer a local copy under TRELLIS_MODELS_DIR/<org>--<repo>/ if available.
        # This allows calling from_pretrained("microsoft/TRELLIS.2-4B") while fully offline.
        models_dir = os.environ.get("TRELLIS_MODELS_DIR")
        if not models_dir:
            models_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "models"))
            if not os.path.isdir(models_dir):
                models_dir = None
        if models_dir and isinstance(path, str) and "/" in path and not os.path.exists(path):
            parts = path.split("/")
            if len(parts) >= 2:
                repo_id = f"{parts[0]}/{parts[1]}"
                local_repo_dir = os.path.join(models_dir, repo_id.replace("/", "--"))
                if os.path.isdir(local_repo_dir):
                    path = local_repo_dir

        is_local = os.path.exists(os.path.join(path, config_file))

        if is_local:
            config_file = os.path.join(path, config_file)
        else:
            from huggingface_hub import hf_hub_download
            config_file = hf_hub_download(path, config_file)

        with open(config_file, 'r') as f:
            args = json.load(f)['args']

        _models = {}
        if ignore_models is None:
            ignore_models = []

        _models = {}
        for k, v in args['models'].items():
            if k in ignore_models:
                continue
            if hasattr(cls, 'model_names_to_load') and k not in cls.model_names_to_load:
                continue
            try:
                _models[k] = models.from_pretrained(f"{path}/{v}")
            except Exception as e:
                _models[k] = models.from_pretrained(v)

        new_pipeline = cls(_models)
        new_pipeline._pretrained_args = args
        return new_pipeline

    @property
    def device(self) -> torch.device:
        if hasattr(self, '_device'):
            return self._device
        for model in self.models.values():
            if hasattr(model, 'device'):
                return model.device
        for model in self.models.values():
            if hasattr(model, 'parameters'):
                return next(model.parameters()).device
        raise RuntimeError("No device found.")

    def to(self, device: torch.device) -> None:
        for model in self.models.values():
            model.to(device)

    def cuda(self) -> None:
        self.to(torch.device("cuda"))

    def cpu(self) -> None:
        self.to(torch.device("cpu"))